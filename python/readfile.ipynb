{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "from camera_conventions.parser import parse_ini_convention\n",
    "Blender = parse_ini_convention('../conventions/Blender.ini')\n",
    "\n",
    "OpenGL = parse_ini_convention('../conventions/OpenGL.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camera_conventions.geometry import Geometry\n",
    "\n",
    "arr = np.array([    \n",
    "    0.0, 0.2, 0.5,\n",
    "    0.2, -0.1, 0.3,\n",
    "    0.2, -0.1, 0.7,\n",
    "    0.0, 0.2, 0.5, \n",
    "    -0.2, -0.1, 0.7,\n",
    "    0.2, -0.1, 0.7,\n",
    "    0.0, 0.2, 0.5, \n",
    "    -0.2, -0.1, 0.3,\n",
    "    -0.2, -0.1, 0.7,\n",
    "    0.0, 0.2, 0.5,      \n",
    "    -0.2, -0.1, 0.3,\n",
    "    0.2, -0.1, 0.3,\n",
    "    0.2, -0.1, 0.3, \n",
    "    0.2, -0.1, 0.7,\n",
    "    -0.2, -0.1, 0.7,\n",
    "    -0.2, -0.1, 0.3, \n",
    "    0.2, -0.1, 0.3,\n",
    "    -0.2, -0.1, 0.7]).reshape(-1, 3)\n",
    "colors = np.array([\n",
    "    1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0,\n",
    "                  0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
    "                  0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0,\n",
    "                  1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
    "                  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0\n",
    "]).reshape(-1, 3)\n",
    "colors = (colors * 255).astype(np.uint8)\n",
    "arr[:, 2] -= 0.5\n",
    "verts = arr\n",
    "faces = np.arange(0, verts.shape[0]).reshape(-1, 3)\n",
    "geom = Geometry(convention=OpenGL, verts=verts, faces=faces, vertex_colors=colors)\n",
    "geom.to_json('../assets/geometries/pyramid.json')\n",
    "geom.convert(Blender).to_json('../assets/geometries/pyramid_blender.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678,  0.        ,  0.70710678,  1.        ],\n",
       "       [ 0.70710678,  0.        ,  0.70710678,  1.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from camera_conventions.camera import Camera\n",
    "\n",
    "\"\"\"\n",
    "(((-0.7071067690849304, 3.0908619663705394e-08, 0.7071067690849304, 1.0),\n",
    "        (0.7071067690849304, 3.0908619663705394e-08, 0.7071067690849304, 1.0),\n",
    "        (0.0, 1.0, -4.371138828673793e-08, 0.0),\n",
    "        (0.0, 0.0, 0.0, 1.0)))\n",
    "\"\"\"\n",
    "bTestCam = Camera(\n",
    "    convention=Blender,\n",
    "    fhat=50.0 / 36.0,\n",
    "    aspect_ratio=1.5,\n",
    "    T=np.array(\n",
    "        [\n",
    "            [-np.sqrt(2) / 2, 0, np.sqrt(2) / 2, 1.0],\n",
    "            [np.sqrt(2) / 2, 0, np.sqrt(2) / 2, 1.0],\n",
    "            [0, 1.0, 0, 0],\n",
    "            [0, 0, 0, 1.0],\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "bTestCam.to_json('../assets/cameras/testCam_blender.json')\n",
    "bTestCam.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70710678,  0.        , -0.70710678,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.70710678,  0.        ,  0.70710678, -1.41421356],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rt, C = bTestCam.T[:3, :3], bTestCam.T[:3, 3]\n",
    "blender_to_opengl = np.linalg.inv(Blender.world_transformation_matrix)\n",
    "Rt_opengl = blender_to_opengl @ Rt\n",
    "C_opengl = blender_to_opengl @ C\n",
    "opengl_T = np.eye(4)\n",
    "opengl_T[:3, :3] = Rt_opengl\n",
    "opengl_T[:3, 3] = C_opengl\n",
    "opengl_T = np.linalg.inv(opengl_T)\n",
    "opengl_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70710678,  0.        , -0.70710678,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.70710678,  0.        ,  0.70710678, -1.41421356],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opengl_to_blender = np.eye(4)\n",
    "opengl_to_blender[:3, :3] = np.linalg.inv(blender_to_opengl)\n",
    "np.linalg.inv(bTestCam.T) @ opengl_to_blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70710678,  0.        , -0.70710678,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.70710678,  0.        ,  0.70710678, -1.41421356],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bTestCam.convert(OpenGL).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(bTestCam.convert(OpenGL).convert(Blender).T, bTestCam.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bTestCam.convert(OpenGL).to_json('../assets/cameras/testCam.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Camera(fhat=3.2654622395833335, T=array([[ 0.44548106, -0.02055738, -0.89505532, -1.47978022],\n",
       "       [-0.04920658,  0.99766302, -0.04740482, -0.14007912],\n",
       "       [ 0.89393811,  0.06516056,  0.44342842,  0.70026039],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), aspect_ratio=0.52734375, convention=AliceVision)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AliceVision = parse_ini_convention('../conventions/alicevision.ini')\n",
    "with open('../assets/cameras/robCam.txt') as f:\n",
    "    for i in range(3):\n",
    "        f.readline()\n",
    "    T = np.array(list(map(float, f.read().split()))).reshape(4, 4)\n",
    "    T[:3, 3] /= 100\n",
    "alicecam = Camera(\n",
    "    fhat=  20063 / 6144,\n",
    "    convention = AliceVision,\n",
    "    aspect_ratio=3240 / 6144,\n",
    "    T = T\n",
    ")\n",
    "alicecam.convert(Blender).to_json('../assets/cameras/robCam_blender.json')\n",
    "alicecam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Camera(fhat=3.2655901054237084, T=array([[ 0.44548106, -0.02055738, -0.89505532, -1.47978022],\n",
       "       [-0.04920658,  0.99766302, -0.04740482, -0.14007912],\n",
       "       [ 0.89393811,  0.06516056,  0.44342842,  0.70026039],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), aspect_ratio=0.52734375, convention=AliceVision)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from camera_conventions.camera import parse_alicevision_camera\n",
    "parse_alicevision_camera(\"/nas/RobFacialPerformace/00/cameras/camera0.txt\", AliceVision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.68927401, -0.02129507, -0.72418785,  0.01974773],\n",
       "       [ 0.17949615, -0.96338564,  0.19917126, -0.00862858],\n",
       "       [-0.70191354, -0.26727247, -0.66021425,  1.1254487 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nersem_js = json.load(open('/nas/data/nersemble/017/camera_params.json', 'rt'))\n",
    "nersem_int = np.array(nersem_js['intrinsics'])\n",
    "nersem_ext = np.array(nersem_js['world_2_cam']['222200042'])\n",
    "Nersemble = parse_ini_convention('../conventions/nersemble.ini')\n",
    "nersem_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Camera(fhat=2.5522328517086192, T=array([[ 0.68927401, -0.02129507, -0.72418785,  0.01974773],\n",
       "       [ 0.17949615, -0.96338564,  0.19917126, -0.00862858],\n",
       "       [-0.70191354, -0.26727247, -0.66021425,  1.1254487 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), aspect_ratio=0.685785536159601, convention=NerSemble)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_cam = Camera(\n",
    "    fhat = nersem_int[0, 0] / 3208,\n",
    "    convention = Nersemble,\n",
    "    aspect_ratio = 2200 / 3208,\n",
    "    T = nersem_ext\n",
    ")\n",
    "ner_cam.to_json('../assets/cameras/nersem_cam.json')\n",
    "ner_cam.convert(Blender).to_json('../assets/cameras/nersem_cam_blender.json')\n",
    "ner_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0., -0.],\n",
       "       [ 0., -1., -0.],\n",
       "       [ 0.,  0., -1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nersemble.camera_transformation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaussian-avatars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
